---
layout:     post
title:      "Lymann alpha Forest & BAO"
subtitle:   "Report on Lecture <i> Cosmic web </i>"
date:       2000-01-02
author:     "Mingjie"
header-img: "img/post-bg-LF-report.jpg"
comments:   true
tags:
      - learning
---

### What is Lymann-$$ \alpha $$ Forest?

![](https://www.nature.com/nature/journal/v440/n7088/images/nature04805-f2.2.jpg)
*Ly-$$ \alpha $$ forest example of QSO 1422+2309 (top panel), the interpertation of formation of the forest (middle panel), and a zoom of the spectra (bottom panel). [Springel et al. (2006)](https://www.nature.com/nature/journal/v440/n7088/full/nature04805.html)*

When we look at the spectra of a quasar, we will find there is an area with very dense absorption lines blueward to the Lymann-$$ \alpha $$ emission line wavelength. This area looks like the forest, so it is called "Lymann-$$ \alpha $$ Forest". Ly-$$ \alpha $$ forest, combined with two other kinds of absorption line (broad and narrow absorption line), raised a debate on their origin. It turned out that broad lines are from quasars themselves, while narrow lines as well as Ly-$$ \alpha $$ forest comes from the galaxies and neutral hydrogen located in the line-of-sight between quasar and us. 

Photons with a wavelength of 1216 Angstrom may be absorbed by a neutral hydrogen cloud in the line-of-sight between quarar and us. Although the absosption will always happenes in 1216 Angstrom, the spectra of quasar, becuase of the expension of Universe, will not stay in the same place. As the photon going through the expanding Universe, its wavelength will increase, that is, the whole spectra will have a redshift while the Lymann-$$ \alpha $$ absorption is still in the same wavelength. Thus those dense absorption forest are mainly caused by one absorption (some other lines suc as Lymann-$$ \beta $$ will also cause a "forest", but much weaker than Lymann-$$ \alpha $$). 

A clear interpertation video is presented [here](https://www.youtube.com/watch?v=6Bn7Ka0Tjjw).

### Why Ly-$$ \alpha $$ Forest can be used as Cosmological Tool?

Because the absorption which should be in the same wavelength now shifted to a wavelength range corresponding to quasar's redshift, the absorption maps the situation of neutral hydrogen between the redshiftted Lymann-$$ \alpha $$ line of quasar and 1216 Angstrom, and we can derive the distribution from what we have observed in the telescopes. 

Furthermore, simulation and measurement of Lymann-$$ \alpha $$ line's broadning indicate that density of neutral hydrogen cloud is low, and their temperature is between $$ 10^4 $$ and $$ 2 \times 10^4 $$. Compared to gravity, pressure forces will be small, so the behaviour of neutral hydrogen will basically be the same as dark metter. As a result, we can trace density distribution also from that of neutral hydrogen. 

Last but not least, the relation between observed flux in a peticular wavlength and density in that distance can be determined, both from a complex relation or a easier method ([Gallerani et al. 2011](#ref), see next section)

In short, the reason Ly-$$ \alpha $$ forest can be used as cosmological tool is by measuring it, we can constrain some parameters of our modeled cosmolog, or, in reverse, we can create the model Ly-$$ \alpha $$ forest and it looks like what we actually observed. 

### How to constrain the model of Cosmology using Ly-$$ \alpha $$ Forest?

To constrain the cosmological parameters we have to first translate obserrved spectra to density fluctuation. It can be done by driectly derive the realtion from physical image, or using a more practicle way. [Gallerani et al. 2011](#ref) discribed both methods and it is worth repeating this here.

Since distribution of neutral hydrogen cloud is not homogenius along line-of-sight (LOS) between quasar and us, we have to treat each wavelength, or distance sepeartely. We first divide the LOS into $$ N $$ bins, then as the difinition of optical depth, we have,

$$ \frac{F(i)}{F_c} = e^{-\tau(i)} $$

where $$ \tau(i) $$ is,

$$ \tau(i) = cI_\alpha \frac{\Delta x}{1+z(i)} \sum_{j=1}^{N} n_\mathrm{HI}(j)\Phi_\alpha[v_H(i) - v_H(j)] $$

here $$ c $$ is light speed, $$ I_\alpha $$ represent the cross-sention of hydrogen, $$ \Delta x$$ the bin length in comoving coordinate, $$ \Phi_\alpha $$ is Voigt profile and $$ n_\mathrm{HI} $$ is neutral hydrogen fraction.

Neutral hydrogen cloud is in a low density situation, so it's easily ionized. We can assume that the cloud is in the equilibrium of ionizaiton and recombination, then $$ n_\mathrm{HI} $$ can be express as:

$$ n_\mathrm{HI} \propto \frac{T_0\Delta(j)^{-0.7(\gamma-1)}}{\Gamma} n_0^2 [1+z(j)]^3 \Delta(j)^2 \propto \Delta(j)^\beta, 1.5 < \beta < 2.0 $$

where $$ T_0 $$ is IGM density at mean density at redshift $$ z(j) $$, $$ \gamma $$ (slope of equation of state) indicate the reionization history of Universe, $$ \Gamma $$ represent the photoionization rate at given $$ z(j) $$, and $$ \Delta(j) $$ is the over density in a given $$ j $$. So we can see here $$ \tau(i) $$ is related to the property of hydrogen cloud, reionization history of Universe and profile of hydrogen absorption line (if assume Gaussian, it still related to thermal state of the gas). 

This is the reason stating direct derivation of flux-density relation is very complex; it convolutes too many factors that makes cauculation impossible or lossing accuracy if introducing more assumption. However, by using probability distribution function (PDF), this relation can be determined by computation.

Let us now consider the PDF of observed, or transmitte flux $$ F $$ as well as over density $$ \delta $$. Here it is assumed that an over density $$ \delta_* $$ is associated to a single value of $$ F_* $$, so from the conservation of probability, integral from $$ 0 $$ to $$ F_* $$ must be equal to intergration from $$ \Delta_* $$ to $$ \infty $$, that is,

$$ \int_0^{F_*} P_F dF = \int_{\Delta_*}^\infty P_\Delta d\Delta $$

or vise versa, 

$$ \int_{F_*}^1 P_F dF = \int_0^{\Delta_*} P_\Delta d\Delta $$

Of course, observation will always be accompanied by uncertainties, so when the flux is very close to 0 or 1 we cannot tell the small discrepncy from 0 or 1 is from absorption or error. To account for this, one maximum and minimum flux ($$ F_\mathrm{max}, F_\mathrm{min} $$) and the corresponding minimum and maximum optical depth ($$ \Delta_\mathrm{min}, \Delta_\mathrm{max} $$) is set as the boundary of the integral,

$$ \int_{F_\mathrm{min}}^{F_*} P_F dF = \int_{\Delta_*}^{\Delta_\mathrm{max}} P_\Delta d\Delta $$

$$ \int_{F_*}^{F_\mathrm{max}} P_F dF = \int_{\Delta_\mathrm{min}}^{\Delta_*} P_\Delta d\Delta $$

By solving these equations, we can get the realtion of $$ F $$ and $$ \Delta $$, then convert the observed spectra to over density. Simulation have shown that after setting a aset of parameters $$ (\beta, \Gamma, T_0, \gamma) $$, both the spectra and distribution of over density can be recover well.

![](/img/in-post/post-LF-report/2-3Dd.png)
*From [Gallerani et al. 2011](#ref)*

So now we cam determine a 1-dimentional density fluctuation long one LOS; this is far from enough to constrain the cosmological model. But if we have a large number of quasars spreading over a large area of celestial sphere, then it will be possible to achieve 3-D density field. Luckily, [BOSS](http://www.sdss.org/surveys/boss/) survey fron SDSS provides this possbiblity. 

![](http://cdn.iopscience.com/images/1538-3881/145/1/10/Full/aj451111f1_lr.jpg)
*Footprint of BOSS; from [Dawson et al. 2013](http://adsabs.harvard.edu/abs/2013AJ....145...10D)*



#### Recovering topology and power spectrum

Although with the data of BOSS survey, 3-D density distribution is possible to be derived, the separation of each quasar in slightly shifted LOS block us from directly detecting the distribution in between. As a result, interpolation have to be done from discretely LOS.

Both [Caucci ei al. 2008](#ref) and [Kitaura et al. 2012](#ref) use a Bayesian method to interpolate. A detailed description is present in [Pichon et al.](#ref), and here only a summarize of this metod will be present.

The relation between optical depth and neutral hydrogen is,

$$ \tau_l(w) = \frac{c\sigma_0}{H(\bar{z})\sqrt{\pi}} \int \int [\int_{-\infty}^{\infty} \frac{n_\mathrm{HI}(x,x_)}]

With some assumption of dark matter, we can translate $$ n_\mathrm{HI} $$ to density of dark matter $$ \rho_\mathrm{DM} $$. However this relation still depends on many other parameters, so wen have to determine them first.

Combining all those paremeters, we can make an array, $$ \mathbf{M} $$, and what we want now is the probability of getting $$ \mathbf{M} $$ from a given data, $$ \mathbf{D} $$, and according to Bayesian theorem, we have,

$$ f(\mathbf{M} | \mathbf{D}) = L(\mathbf{D} | \mathbf{M})f(\mathbf{M}) $$

which we can (though still a little complicated), compute the likelihood $$ L(\mathbf{D} \| \mathbf{M}) $$ and derive the prior \\( f(\mathbf{M}) \\) under some observation. Then, after holding the 3-D density result, visulization can be easily done.

[Caucci ei al. 2008](#ref) recover the tropology of HI density field at redshift of 2 simulated by model. The result looks very consistent with the simulated data.

![](/img/in-post/post-LF-report/3-topology.png)

#### Measureing BAO feature from correlation function

Reality research will always be limited by observation.

<p id = "ref"></p>
---
### References

---

